import base64
import mimetypes
import os
import shutil
import tempfile
import uuid
from collections import Counter
from datetime import timedelta
from urllib.parse import quote_plus, urljoin
from django.shortcuts import get_object_or_404
from django.http import FileResponse, HttpResponseRedirect
from django.urls import reverse
from django.conf import settings
from django.core import signing
from django.core.mail import send_mail
from rest_framework.decorators import api_view, parser_classes
from rest_framework.parsers import MultiPartParser, JSONParser, FormParser
from rest_framework.response import Response
from rest_framework import  generics
from django.utils import timezone
from cryptography.fernet import InvalidToken
from django.utils.dateparse import parse_datetime
from django.db import transaction
from django.db.models import Count
from rest_framework import permissions
from rest_framework.decorators import permission_classes
from drf_spectacular.utils import (
    extend_schema,
    extend_schema_view,
    OpenApiResponse,
    OpenApiExample,
    OpenApiParameter,
)
from drf_spectacular.types import OpenApiTypes
from django.core.cache import cache
from django.core.files.base import ContentFile

from .models import (
    Bucket, StorageFolder, StorageObject, ObjectVersion,
    EncryptionType, ObjectChangeLog, AccessControlList, PublicShareLink, ShareScope
)
from .serializers import (
    BucketSerializer,
    ObjectSerializer,
    ObjectVersionSerializer,
    TrashEntrySerializer,
    TrashDeleteRequestSerializer,
    SharedWithMeSerializer,
    PublicShareLinkSerializer,
)
from . import helpers
from .tasks import build_preview_async


# ================== REDIS CACHE HELPERS ==================
def _ck(*parts):
    return "cloud:" + ":".join(str(p) for p in parts).replace(" ", "_")


def invalidate_bucket_caches(bucket, user_id=None):
    try:
        keys = [
            _ck("bucket_detail", bucket.name),
            _ck("list_objects", bucket.name, user_id or getattr(bucket.owner, "id", "")),
            _ck("bucket_status", bucket.name),
            _ck("bucket_stats", bucket.id),
        ]
        if user_id or getattr(bucket.owner, "id", None):
            uid = user_id or bucket.owner.id
            keys.extend([
                _ck("user_summary", uid),
                _ck("bucket_list", uid),
            ])
        cache.delete_many(keys)
    except Exception:
        pass


TEXT_MIME_EXTRA = {"application/json", "application/javascript", "application/xml"}
SHARE_TOKEN_SALT = "share-object-token"
OFFICE_MIME_TYPES = {
    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "application/vnd.openxmlformats-officedocument.presentationml.presentation",
    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
}
OFFICE_EXTS = {".doc", ".docx", ".xls", ".xlsx", ".ppt", ".pptx"}
OFFICE_MIME_MAP = {
    ".doc": "application/msword",
    ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    ".xls": "application/vnd.ms-excel",
    ".xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    ".ppt": "application/vnd.ms-powerpoint",
    ".pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
}


def _is_text_mime(mime: str) -> bool:
    if not mime:
        return False
    return mime.startswith("text/") or mime in TEXT_MIME_EXTRA


def _is_office_file(obj: StorageObject) -> bool:
    mime = obj.content_type or ""
    if mime in OFFICE_MIME_TYPES:
        return True
    ext = os.path.splitext(obj.key)[1].lower()
    return ext in OFFICE_EXTS


def _normalize_office_mime(obj: StorageObject, mime: str) -> str:
    ext = os.path.splitext(obj.key)[1].lower()
    if mime in OFFICE_MIME_TYPES:
        return mime
    if ext in OFFICE_EXTS:
        return OFFICE_MIME_MAP.get(ext, mime or "application/octet-stream")
    return mime


def _build_public_url(path: str, request=None) -> str:
    """
    Build absolute URL using PUBLIC_BASE_URL if configured; fallback to request host.
    """
    public_base = getattr(settings, "PUBLIC_BASE_URL", "").rstrip("/")
    if public_base:
        return urljoin(public_base + "/", path.lstrip("/"))
    if request:
        # Respect forwarded proto (ngrok sends https) or force https for ngrok host
        proto = request.headers.get("X-Forwarded-Proto") or request.scheme or "http"
        host = request.get_host()
        if host.endswith(".ngrok-free.dev") and proto != "https":
            proto = "https"
        return f"{proto}://{host}{path}"
    return path


def _remove_physical_file(obj: StorageObject):
    """
    Delete physical file from disk, handling optional encryption suffix.
    """
    target_path = obj.storage_path
    if obj.status_encrypt and target_path and not target_path.endswith(".enc"):
        encrypted_path = f"{target_path}.enc"
        if os.path.exists(encrypted_path):
            target_path = encrypted_path
    if target_path and os.path.exists(target_path):
        try:
            os.remove(target_path)
        except Exception:
            pass


def ensure_folder_entries(bucket, raw_path, owner):
    """
    T?o c�c b?n ghi StorageFolder cho du?ng d?n n?u chua t?n t?i.
    """
    cleaned = (raw_path or "").strip().lstrip("/").rstrip("/")
    if not cleaned:
        return None

    parent = None
    current_path = ""
    for part in cleaned.split("/"):
        if not part:
            continue
        current_path = f"{current_path}{part}/" if not current_path else f"{current_path}{part}/"
        folder, _ = StorageFolder.objects.get_or_create(
            bucket=bucket,
            path=current_path,
            defaults={
                "name": part,
                "parent": parent,
                "owner": owner,
            },
        )
        parent = folder
    return parent


def _build_share_token(bucket_name: str, key: str, expires_minutes: int, passcode: str | None = None) -> str:
    payload = {
        "bucket": bucket_name,
        "key": key,
        "exp": (timezone.now() + timedelta(minutes=expires_minutes)).timestamp(),
    }
    if passcode:
        payload["passcode"] = passcode
    return signing.dumps(payload, salt=SHARE_TOKEN_SALT)


def _load_share_token(token: str):
    try:
        data = signing.loads(token, salt=SHARE_TOKEN_SALT)
    except signing.BadSignature:
        raise ValueError("Token không hợp lê")
    exp = data.get("exp")
    if exp and timezone.now().timestamp() > exp:
        raise ValueError("Token đã hết hạn")
    return data


# =====================================================
# ?? BUCKET CRUD
# =====================================================

@extend_schema_view(
    post=extend_schema(
        tags=["Buckets"],
        summary="Create bucket",
        request=BucketSerializer,
        responses={201: BucketSerializer, 400: OpenApiResponse(description="Validation error")},
    )
)
class CreateBucketView(generics.CreateAPIView):
    serializer_class = BucketSerializer
    permission_classes = [permissions.IsAuthenticated]

    def perform_create(self, serializer):
        serializer.save(owner=self.request.user)


@extend_schema_view(
    get=extend_schema(
        tags=["Buckets"],
        summary="List my buckets",
        responses={200: BucketSerializer(many=True)},
    )
)
class ListBucketsView(generics.ListAPIView):
    serializer_class = BucketSerializer
    permission_classes = [permissions.IsAuthenticated]

    def get_queryset(self):
        return Bucket.objects.filter(owner=self.request.user).order_by("-created_at")

    def list(self, request, *args, **kwargs):
        cache_key = _ck("bucket_list", request.user.id)
        cached = cache.get(cache_key)
        if cached is not None:
            return Response(cached)
        queryset = self.get_queryset()
        serializer = self.get_serializer(queryset, many=True)
        data = serializer.data
        cache.set(cache_key, data, timeout=60)
        return Response(data)
    

@extend_schema(
    tags=["Sync"],
    summary="List changes since timestamp",
    parameters=[
        OpenApiParameter(
            name="since",
            description="ISO datetime, e.g. 2025-10-27T08:00:00Z",
            required=False,
            type=OpenApiTypes.DATETIME,
            location=OpenApiParameter.QUERY,
        )
    ],
    responses={200: OpenApiResponse(description="{ 'changes': [...] }", examples=[
        OpenApiExample("changes", value={"changes": [{"bucket": "my-bucket", "key": "a/b.txt", "action": "created", "version_id": "abc123", "size": 10, "timestamp": "2025-10-27T08:01:00Z"}]})
    ])}
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def sync_changes(request):
    """
    L?y danh s�ch thay d?i sau th?i di?m nh?t d?nh
    ?since=2025-10-27T08:00:00Z
    """
    user_id = request.user.id
    since_str = request.GET.get("since")
    since = parse_datetime(since_str) if since_str else None

    logs = ObjectChangeLog.objects.filter(user_id=user_id)
    if since:
        logs = logs.filter(timestamp__gt=since)

    data = [
        {
            "bucket": log.bucket.name,
            "key": log.key,
            "action": log.action,
            "version_id": log.version_id,
            "size": log.size,
            "timestamp": log.timestamp.isoformat()
        }
        for log in logs.order_by("timestamp")
    ]
    return Response({"changes": data})

# ================== CREATE FOLDER ==================
@extend_schema(
    tags=["Folders"],
    summary="Create folder",
    request=OpenApiTypes.OBJECT,
    responses={201: OpenApiResponse(description="Created"), 400: OpenApiResponse(description="Invalid name")},
    examples=[OpenApiExample("payload", value={"folder_path": "TEST/documents/"}, request_only=True)],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def create_folder(request, bucket_name):
    """
    T?o folder m?i
    Body: {"folder_path": "TEST/documents/"}
    """
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n trong bucket n�y"}, status=403)

    folder_path = request.data.get("folder_path", "").strip().lstrip("/").rstrip("/") + "/"
    if not folder_path or len(folder_path) > 255:
        return Response({"error": "T�n folder kh�ng h?p l?"}, status=400)

    if StorageFolder.objects.filter(bucket=bucket, path=folder_path).exists():
        return Response({"message": "Folder d� t?n t?i"}, status=200)

    try:
        with transaction.atomic():
            parts = folder_path.rstrip("/").split("/")
            current_path = ""
            parent = None
            created_folders = []

            for part in parts:
                current_path = f"{current_path}{part}/" if not current_path else f"{current_path}{part}/"
                folder, created = StorageFolder.objects.get_or_create(
                    bucket=bucket,
                    path=current_path,
                    defaults={
                        "name": part,
                        "parent": parent,
                        "owner": bucket.owner,
                    }
                )
                parent = folder
                created_folders.append({"name": folder.name, "path": folder.path, "created": created})

    
                helpers.get_folder_physical_path(bucket, current_path)

            helpers.log_change(bucket.owner.id, bucket, folder_path, "created")
    except Exception as e:
        return Response({"error": f"Lỗi khi tạo thư mục: {str(e)}"}, status=500)

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass

    return Response({"message": "Tạo folder thành công", "created_folders": created_folders}, status=201)


# ================== DELETE FOLDER ==================
@extend_schema(
    tags=["Folders"],
    summary="Delete folder",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Deleted summary"), 404: OpenApiResponse(description="Not found")},
    examples=[OpenApiExample("payload", value={"folder_path": "TEST/documents/", "hard": False}, request_only=True)],
)
@api_view(["DELETE"])
@permission_classes([permissions.IsAuthenticated])
def delete_folder(request, bucket_name):
    """
    Xóa folder và tắt cả subfolder, file bên trong
    Body: {"folder_path": "TEST/documents/", "hard": False}  # hard=True n?u mu?n x�a th?t
    """
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "Bạn không có quyền xóa"}, status=403)

    folder_path = request.data.get("folder_path", "").strip().rstrip("/") + "/"
    hard_delete = request.data.get("hard", False)

    if not folder_path or folder_path == "/":
        return Response({"error": "folder_path không hợp lý?"}, status=400)

    folder = StorageFolder.all_objects.filter(bucket=bucket, path=folder_path).first()
    if not folder:
        return Response({"error": "Không tìm thấy thư mục cần xóa"}, status=404)

    related_objects = StorageObject.all_objects.filter(bucket=bucket, key__startswith=folder_path)
    related_folders = StorageFolder.all_objects.filter(bucket=bucket, path__startswith=folder_path)

    deleted_files = []
    deleted_folders = []

    with transaction.atomic():
  
        for obj in related_objects:
            deleted_files.append(obj.key)
            obj.delete(hard=hard_delete)

        for f in related_folders:
            deleted_folders.append(f.path)
            f.delete(hard=hard_delete)

    if hard_delete:
        try:
            physical_path = helpers.get_folder_physical_path(bucket, folder_path)
            if os.path.exists(physical_path):
                shutil.rmtree(physical_path)
        except Exception as e:
            print(f"?? L?i x�a folder v?t l�: {e}")

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass

    return Response({
        "message": "X�a folder th�nh c�ng",
        "folder_path": folder_path,
        "deleted_folders": deleted_folders,
        "deleted_files": deleted_files,
        "count_files": len(deleted_files),
        "count_folders": len(deleted_folders),
        "hard_delete": hard_delete
    }, status=200)

# ================== MOVE FOLDER ==================
@extend_schema(
    tags=["Folders"],
    summary="Move folder",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Moved"), 404: OpenApiResponse(description="Not found")},
    examples=[OpenApiExample("payload", value={"source_path": "documents/", "destination_path": "TEST/images/"}, request_only=True)],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def move_folder(request, bucket_name):
    """
    Di chuy?n folder (c?p nh?t c? DB + filesystem)
    Body: {"source_path": "documents/", "destination_path": "TEST/images/"}
    """
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n move folder"}, status=403)

    # Th�m "/" cu?i cho chu?n
    source_path = request.data.get("source_path", "").strip().rstrip("/") + "/"
    dest_path = request.data.get("destination_path", "").strip().rstrip("/") + "/"

    if not source_path:
        return Response({"error": "Thi?u source_path"}, status=400)

    folder = StorageFolder.objects.filter(bucket=bucket, path=source_path).first()
    if not folder:
        return Response({"error": f"Kh�ng t�m th?y folder ngu?n: {source_path}"}, status=404)


    parent_folder = StorageFolder.objects.filter(bucket=bucket, path=dest_path).first() if dest_path != "/" else None
    if dest_path != "/" and not parent_folder:
        return Response({"error": f"Folder d�ch kh�ng t?n t?i: {dest_path}"}, status=404)


    new_path = f"{dest_path}{folder.name}/" if dest_path != "/" else f"{folder.name}/"

    base_dir = helpers.get_bucket_base_dir(bucket)
    old_dir = os.path.join(base_dir, *source_path.rstrip("/").split("/"))
    dest_dir = os.path.join(base_dir, *new_path.rstrip("/").split("/"))
    os.makedirs(os.path.dirname(dest_dir), exist_ok=True)

    try:
        if not os.path.exists(old_dir):
            return Response({"error": f"Thu m?c v?t l� ngu?n kh�ng t?n t?i: {old_dir}"}, status=404)
        if os.path.exists(dest_dir):
            return Response({"error": f"Folder d�ch d� t?n t?i: {dest_dir}"}, status=409)
        shutil.move(old_dir, dest_dir)
    except Exception as e:
        return Response({"error": f"L?i khi di chuy?n folder: {e}"}, status=500)

    with transaction.atomic():
  
        folder.path = new_path
        folder.parent = parent_folder
        folder.save(update_fields=["path", "parent"])

 
        subfolders = StorageFolder.objects.filter(bucket=bucket, path__startswith=source_path).exclude(id=folder.id)
        for sf in subfolders:
            sf.path = sf.path.replace(source_path, new_path, 1)
            parent_sf_path = "/".join(sf.path.rstrip("/").split("/")[:-1]) + "/"
            sf.parent = StorageFolder.objects.filter(bucket=bucket, path=parent_sf_path).first() if parent_sf_path != "/" else None
            sf.save(update_fields=["path", "parent"])

      
        objects = StorageObject.objects.filter(bucket=bucket, key__startswith=source_path)
        for obj in objects:
            obj.key = obj.key.replace(source_path, new_path, 1)
            obj.storage_path = os.path.join(base_dir, *obj.key.split("/"))
            obj.save(update_fields=["key", "storage_path"])

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass
    return Response({
        "message": "Move folder th�nh c�ng",
        "old_path": source_path,
        "new_path": new_path
    }, status=200)

# ================== COPY FOLDER ==================
@extend_schema(
    tags=["Folders"],
    summary="Copy folder",
    request=OpenApiTypes.OBJECT,
    responses={201: OpenApiResponse(description="Copied summary")},
    examples=[OpenApiExample("payload", value={"source_path": "TEST/documents/", "destination_path": "TEST/COPY/"}, request_only=True)],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def copy_folder(request, bucket_name):
    """
    Copy folder trong bucket, bao g?m subfolders v� files
    Body:
    {
        "source_path": "TEST/documents/",   # folder ngu?n, ph?i c� "/"
        "destination_path": "TEST/COPY/"    # folder d�ch, ph?i c� "/"
    }
    """
    import shutil
    import os
    from django.db import transaction

    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n copy"}, status=403)

    source_path = request.data.get("source_path", "").strip().lstrip("/").rstrip("/") + "/"
    dest_path = request.data.get("destination_path", "").strip().lstrip("/").rstrip("/") + "/"

    if not source_path or not dest_path:
        return Response({"error": "Thi?u source_path ho?c destination_path"}, status=400)

    if source_path == dest_path:
        return Response({"error": "Kh�ng th? copy v�o c�ng v? tr�"}, status=400)

    source_folder = StorageFolder.objects.filter(bucket=bucket, path=source_path).first()
    if not source_folder:
        return Response({"error": f"Kh�ng t�m th?y folder ngu?n: {source_path}"}, status=404)

    base_dir = helpers.get_bucket_base_dir(bucket)
    old_dir = os.path.join(base_dir, *source_path.rstrip("/").split("/"))


    new_folder_name = os.path.basename(source_path.rstrip("/"))
    new_dest_path = os.path.join(dest_path, new_folder_name).replace("\\", "/") + "/"
    counter = 1
    while StorageFolder.objects.filter(bucket=bucket, path=new_dest_path).exists() or os.path.exists(os.path.join(base_dir, *new_dest_path.rstrip("/").split("/"))):
        new_dest_path = os.path.join(dest_path, f"{new_folder_name}_copy{counter}").replace("\\", "/") + "/"
        counter += 1

    dest_dir = os.path.join(base_dir, *new_dest_path.rstrip("/").split("/"))
    os.makedirs(os.path.dirname(dest_dir), exist_ok=True)

    copied_files = []

    try:
 
        shutil.copytree(old_dir, dest_dir)
    except Exception as e:
        return Response({"error": f"L?i khi copy folder v?t l�: {str(e)}"}, status=500)

    with transaction.atomic():
        source_folders = StorageFolder.objects.filter(bucket=bucket, path__startswith=source_path)
        for folder in source_folders:
            relative_path = folder.path[len(source_path):]
            folder_path_new = new_dest_path + relative_path
            parent_path = "/".join(folder_path_new.rstrip("/").split("/")[:-1]) + "/"
            parent = StorageFolder.objects.filter(bucket=bucket, path=parent_path).first() if parent_path != "/" else None
            StorageFolder.objects.create(
                bucket=bucket,
                name=folder.name,
                path=folder_path_new,
                owner=bucket.owner,
                parent=parent,
            )

        source_objects = StorageObject.objects.filter(bucket=bucket, key__startswith=source_path)
        for obj in source_objects:
            relative_key = obj.key[len(source_path):]
            new_key = new_dest_path + relative_key
            dst_path = os.path.join(dest_dir, relative_key.replace("/", os.sep))  

            new_obj = StorageObject.objects.create(
                bucket=bucket,
                key=new_key,
                owner=bucket.owner,
                size=obj.size,
                content_type=obj.content_type,
                storage_path=dst_path,
                encryption_type=obj.encryption_type,
                status_encrypt=obj.status_encrypt,
                user_metadata=obj.user_metadata,
                last_modified=timezone.now()
            )
            copied_files.append({"source": obj.key, "destination": new_key, "size": new_obj.size})

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass
    return Response({
        "message": "Copy folder th�nh c�ng",
        "copied_files": copied_files,
        "new_path": new_dest_path,
        "count": len(copied_files)
    }, status=201)

# ================== RENAME FOLDER ==================
@extend_schema(
    tags=["Folders"],
    summary="Rename folder",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Renamed"), 409: OpenApiResponse(description="Destination exists")},
    examples=[OpenApiExample("payload", value={"old_path": "TEST/images/documents/", "new_name": "DOCUMENTS_NEW"}, request_only=True)],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def rename_folder(request, bucket_name):
    """
    Rename folder trong bucket, c?p nh?t DB + filesystem
    Body:
    {
        "old_path": "TEST/images/documents/",  # folder cu, ph?i c� "/"
        "new_name": "DOCUMENTS_NEW"
    }
    """
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n rename folder n�y"}, status=403)

    old_path = request.data.get("old_path", "").strip().lstrip("/").rstrip("/") + "/"
    new_name = request.data.get("new_name", "").strip().rstrip("/")

    if not old_path or not new_name:
        return Response({"error": "Thi?u old_path ho?c new_name"}, status=400)

    folder = StorageFolder.objects.filter(bucket=bucket, path=old_path).first()
    if not folder:
        return Response({"error": f"Kh�ng t�m th?y folder: {old_path}"}, status=404)

    parent_path = "/".join(old_path.rstrip("/").split("/")[:-1])
    parent_path = parent_path + "/" if parent_path else ""
    new_path = f"{parent_path}{new_name}/"

    base_dir = helpers.get_bucket_base_dir(bucket)
    old_dir = os.path.join(base_dir, *old_path.rstrip("/").split("/"))
    new_dir = os.path.join(base_dir, *new_path.rstrip("/").split("/"))

    if os.path.exists(new_dir):
        if old_dir.lower() == new_dir.lower() and os.name == "nt":
            temp_dir = new_dir + "_tmp_rename"
            os.rename(old_dir, temp_dir)
            old_dir = temp_dir
        else:
            return Response({"error": f"Folder d�ch d� t?n t?i: {new_dir}"}, status=409)

    try:
        os.rename(old_dir, new_dir)
    except Exception as e:
        return Response({"error": f"L?i khi rename folder v?t l�: {str(e)}"}, status=500)

    with transaction.atomic():
      
        folder.name = new_name
        folder.path = new_path
        folder.save(update_fields=["name", "path"])

     
        subfolders = StorageFolder.objects.filter(bucket=bucket, path__startswith=old_path).exclude(id=folder.id)
        for sf in subfolders:
            sf.path = sf.path.replace(old_path, new_path, 1)
            parent_sf_path = "/".join(sf.path.rstrip("/").split("/")[:-1]) + "/"
            sf.parent = StorageFolder.objects.filter(bucket=bucket, path=parent_sf_path).first() if parent_sf_path != "/" else None
            sf.save(update_fields=["path", "parent"])

      
        objects = StorageObject.objects.filter(bucket=bucket, key__startswith=old_path)
        for obj in objects:
            obj.key = obj.key.replace(old_path, new_path, 1)
            obj.storage_path = os.path.join(base_dir, *obj.key.rstrip("/").split("/"))
            obj.save(update_fields=["key", "storage_path"])
            helpers.log_change(
                bucket=bucket,
                key=obj.key,
                action="renamed",
                user_id=bucket.owner.id,
                size=obj.size,
                version_id=None
            )

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass
    return Response({
        "message": "Rename folder th�nh c�ng",
        "old_path": old_path,
        "new_path": new_path,
        "old_dir": old_dir,
        "new_dir": new_dir
    }, status=200)


# ================== UPLOAD FOLDER ==================
@extend_schema(
    tags=["Folders"],
    summary="Upload multiple files to folder",
    request={
        'multipart/form-data': OpenApiTypes.OBJECT,
    },
    responses={201: OpenApiResponse(description="Upload result"), 400: OpenApiResponse(description="Validation error")},
)
@api_view(["POST"])
@parser_classes([MultiPartParser, FormParser])
@permission_classes([permissions.IsAuthenticated])
def upload_folder(request, bucket_name):
    """
    Upload nhi?u file v�o m?t thu m?c d� t?n t?i.
    Body:
    {
        "folder_path": "TEST/documents/",  # folder d�ch
        "files": [file1, file2, ...],
        "encryption_type": "NONE" ho?c "AES256"
        "passcode": "123"  # n?u d�ng AES256
    }
    """
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)

 
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n upload"}, status=403)


    folder_path = request.data.get("folder_path", "").strip().lstrip("/").rstrip("/") + "/"
    files = request.FILES.getlist("files")
    passcode = (request.data.get("passcode") or "").strip()
    if passcode and (not passcode.isdigit() or len(passcode) != 6):
        return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)
    encryption_type = EncryptionType.AES256 if passcode else EncryptionType.NONE


    if not folder_path or folder_path == "/":
        return Response({"error": "Thi?u folder_path h?p l?"}, status=400)

    if not files:
        return Response({"error": "Kh�ng c� file n�o du?c upload"}, status=400)

    ensure_folder_entries(bucket, folder_path, bucket.owner)


    base_dir = helpers.ensure_bucket_folder(bucket.name)
    physical_folder_dir = os.path.join(base_dir, folder_path)
    os.makedirs(physical_folder_dir, exist_ok=True)

    uploaded_files = []


    with transaction.atomic():
        for file_obj in files:

          
            key = f"{folder_path}{file_obj.name}"

  
            target_path = os.path.join(physical_folder_dir, file_obj.name)

         
            res = helpers.save_file_to_local(
                bucket_name=bucket.name,
                key=key,
                uploaded_file=file_obj,
                passcode=(passcode if encryption_type == EncryptionType.AES256 else None),
                custom_path=target_path
            )

          
            obj, created = StorageObject.objects.update_or_create(
                bucket=bucket,
                key=key,
                defaults={
                    "owner": user,
                    "size": res["size"],
                    "etag": res["etag"],
                    "content_type": res["content_type"],
                    "storage_path": res["storage_path"],
                    "last_modified": timezone.now(),
                    "encryption_type": encryption_type,
                    "status_encrypt": (encryption_type == EncryptionType.AES256),
                    "user_metadata": {
                        "salt_b64": res.get("salt_b64"),
                        **({"passcode": passcode} if passcode else {}),
                    },
                }
            )

      
            version_id = None
            if bucket.versioning_enabled:
          
                ObjectVersion.objects.filter(object=obj, is_latest=True).update(is_latest=False)

                version_id = uuid.uuid4().hex[:12]
                ObjectVersion.objects.create(
                    object=obj,
                    version_id=version_id,
                    etag=res["etag"],
                    size=res["size"],
                    storage_path=res["storage_path"],
                    is_latest=True,
                    created_at=timezone.now(),
                )

      
            helpers.log_change(
                bucket=bucket,
                key=key,
                action="created",
                user_id=user.id,
                size=res["size"],
                version_id=version_id
            )

         
            uploaded_files.append({
                "id": str(obj.id),
                "key": obj.key,
                "size": obj.size,
                "etag": obj.etag,
                "version_id": version_id,
                "created": created,
                "storage_path": obj.storage_path
            })

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass
    return Response({
        "message": "Upload th�nh c�ng",
        "files": uploaded_files
    }, status=201)


@extend_schema(
    tags=["Folders"],
    summary="Restore soft-deleted folder",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Restored"), 404: OpenApiResponse(description="Not found")},
    examples=[OpenApiExample("payload", value={"path": "TEST/documents/"}, request_only=True)],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def restore_folder(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)

    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n"}, status=403)

    path = request.data.get("path", "").strip().lstrip("/").rstrip("/") + "/"
    if not path:
        return Response({"error": "Thi?u path"}, status=400)

    try:
  
        folder = StorageFolder.all_objects.get(bucket=bucket, path=path)
    except StorageFolder.DoesNotExist:
        return Response({"error": "Kh�ng t�m th?y folder"}, status=404)

    if not folder.is_deleted:
        return Response({"error": "Folder dang ? tr?ng th�i ho?t d?ng"}, status=400)

    with transaction.atomic():

      
        folder.is_deleted = False
        folder.deleted_at = None
        folder.save(update_fields=["is_deleted", "deleted_at"])

        StorageFolder.all_objects.filter(
            bucket=bucket,
            path__startswith=folder.path,
            is_deleted=True
        ).update(is_deleted=False, deleted_at=None)

        StorageObject.all_objects.filter(
            bucket=bucket,
            key__startswith=folder.path,
            is_deleted=True
        ).update(is_deleted=False, deleted_at=None)

      
        ObjectChangeLog.objects.create(
            bucket=bucket,
            key=path,
            action="restored",
            user=user,
            size=0
        )

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass
    return Response({"message": "Kh�i ph?c folder th�nh c�ng", "path": path}, status=200)

# =====================================================
# ?? LIST OBJECTS
# =====================================================
# ===================================================== 
# # ?? METADATA # 
# ===================================================== 
@extend_schema(
    tags=["Objects"],
    summary="Get object metadata",
    responses={200: ObjectSerializer, 403: OpenApiResponse(description="Forbidden"), 404: OpenApiResponse(description="Not found")},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def object_metadata(request, bucket_name, key):
    user = request.user 
    bucket = get_object_or_404(Bucket, name=bucket_name) 
    if bucket.owner != user: 
        return Response({"error": "B?n kh�ng c� quy?n l?y th�ng tin metadata trong bucket n�y"}, status=403) 
    obj = get_object_or_404(StorageObject, bucket=bucket, key=key) 
    cache_key = _ck("object_meta", bucket.name, key)
    data = cache.get(cache_key)
    if data is None:
        data = ObjectSerializer(obj, context={"request": request}).data 
    latest_ver = obj.versions.filter(is_latest=True).first() 
    if latest_ver: 
        data["latest_version_id"] = latest_ver.version_id 
        data["version_count"] = obj.versions.count() 
    cache.set(cache_key, data, timeout=120)
    return Response(data)


@extend_schema(
    tags=["Objects"],
    summary="List folders and objects in the current path",
    parameters=[
        OpenApiParameter(
            name="path",
            description="�u?ng d?n thu m?c hi?n t?i (v� d?: folder/subfolder)",
            required=False,
            type=OpenApiTypes.STR,
            location=OpenApiParameter.QUERY,
        )
    ],
    responses={200: ObjectSerializer(many=True)},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def list_objects(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n l?y danh s�ch file trong bucket n�y"}, status=403)

    raw_path = (request.query_params.get("path") or "").strip()
    normalized_path = raw_path.strip("/").replace("//", "/")
    prefix = f"{normalized_path}/" if normalized_path else ""
    flat_mode = str(request.query_params.get("flat") or "").lower() in {"1", "true", "yes"}

    parent_folder = None
    if normalized_path:
        parent_folder = StorageFolder.objects.filter(
            bucket=bucket, path=f"{normalized_path}/", is_deleted=False
        ).first()

    folder_qs = StorageFolder.objects.filter(
        bucket=bucket, parent=parent_folder, is_deleted=False
    ).order_by("name")
    folder_list = list(folder_qs)

    child_folder_counts = {
        row["parent_id"]: row["total"]
        for row in StorageFolder.objects.filter(
            bucket=bucket, parent__in=folder_list, is_deleted=False
        )
        .values("parent_id")
        .annotate(total=Count("id"))
    }

    objects_qs = StorageObject.objects.filter(bucket=bucket, is_deleted=False)
    if prefix:
        objects_qs = objects_qs.filter(key__startswith=prefix)

    objects_qs = objects_qs.select_related("owner").prefetch_related("versions")

    file_parent_counter = Counter()

    direct_files = []
    for obj in objects_qs.order_by("-last_modified"):
        parent_path_key = obj.key.strip("/")
        if "/" in parent_path_key:
            parent_path_key = parent_path_key.rsplit("/", 1)[0] + "/"
        else:
            parent_path_key = ""
        file_parent_counter[parent_path_key] += 1

        relative_key = obj.key[len(prefix):] if prefix else obj.key
        relative_key = relative_key.strip("/")
        if not flat_mode:
            if "/" in relative_key or not relative_key:
                continue
        display_name = relative_key or os.path.basename(obj.key)
        serialized = ObjectSerializer(obj, context={"request": request}).data
        serialized["name"] = display_name
        serialized["path"] = obj.key
        serialized["is_folder"] = False
        if flat_mode:
            serialized["parentPath"] = os.path.dirname(obj.key).rstrip("/")
        if obj.last_modified:
            serialized["lastModified"] = obj.last_modified.isoformat()
        earliest_version = obj.versions.order_by("created_at").first()
        latest_version = obj.versions.filter(is_latest=True).first()
        serialized["createdAt"] = (
            earliest_version.created_at.isoformat()
            if earliest_version and earliest_version.created_at
            else (obj.last_modified.isoformat() if obj.last_modified else None)
        )
        serialized["ownerName"] = getattr(obj.owner, "full_name", "") if obj.owner_id else ""
        serialized["ownerEmail"] = getattr(obj.owner, "email", "") if obj.owner_id else ""
        serialized["versionCount"] = obj.versions.count()
        serialized["latestVersionId"] = latest_version.version_id if latest_version else None
        serialized["permissions"] = "Ri�ng tu"
        serialized["encryptionType"] = obj.encryption_type
        direct_files.append(serialized)

    folder_data = []
    for folder in folder_list:
        folder_key = folder.path.rstrip("/")
        folder_path = folder.path
        item_count = child_folder_counts.get(folder.id, 0) + file_parent_counter.get(
            folder_path, 0
        )
        folder_data.append(
            {
                "id": str(folder.id),
                "name": folder.name,
                "key": folder_key,
                "path": folder_key,
                "is_folder": True,
                "size": None,
                "items_count": item_count,
                "lastModified": folder.created_at.isoformat(),
            }
        )

    data = folder_data + direct_files
    return Response(data)


@extend_schema(
    tags=["Share"],
    summary="T?o link chia s? c�ng khai",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Share link created"), 400: OpenApiResponse(description="Invalid request")},
    examples=[
        OpenApiExample(
            "payload",
            value={"key": "docs/report.docx", "expires_minutes": 60},
            request_only=True,
        )
    ],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def create_share_link(request, bucket_name):
    user = request.user
    key = (request.data.get("key") or "").strip()
    expires = int(request.data.get("expires_minutes", 60) or 60)
    expires = max(5, min(expires, 1440))
    passcode = (request.data.get("passcode") or "").strip()
    scope_raw = (request.data.get("scope") or ShareScope.ANYONE).lower()
    scope = ShareScope.ANYONE
    if scope_raw in {ShareScope.ANYONE, "anyone"}:
        scope = ShareScope.ANYONE
    elif scope_raw in {ShareScope.SIGNED, "signed"}:
        scope = ShareScope.SIGNED
    elif scope_raw in {ShareScope.CUSTOM, "custom"}:
        scope = ShareScope.CUSTOM
    allow_edit = bool(request.data.get("allow_edit", False))

    custom_emails_raw = request.data.get("custom_emails") or []
    if isinstance(custom_emails_raw, str):
        custom_emails = [e.strip() for e in custom_emails_raw.replace(";", ",").split(",") if e.strip()]
    else:
        custom_emails = [str(e).strip() for e in custom_emails_raw if str(e).strip()]

    if not key:
        return Response({"error": "Thi?u key"}, status=400)

    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n chia s? bucket n�y"}, status=403)

    obj = get_object_or_404(StorageObject, bucket=bucket, key=key, is_deleted=False)
    metadata = obj.user_metadata or {}
    stored_passcode = metadata.get("passcode")

    token_passcode = None
    if obj.encryption_type == EncryptionType.AES256:
        if stored_passcode:
            if passcode and passcode != stored_passcode:
                return Response({"error": "Passcode kh�ng d�ng"}, status=400)
            token_passcode = stored_passcode
        else:
            if not passcode:
                return Response({"error": "File dang m� h�a. Vui l�ng nh?p passcode d? chia s?."}, status=400)
            if not passcode.isdigit() or len(passcode) != 6:
                return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)
            token_passcode = passcode
    elif passcode:
        if not passcode.isdigit() or len(passcode) != 6:
            return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)
        token_passcode = passcode

    token = _build_share_token(bucket.name, key, expires, passcode=token_passcode)
    path_share = reverse("shared_object_download", args=[token])
    share_url = _build_public_url(path_share, request)
    fe_share_base = getattr(settings, "FRONTEND_SHARE_URL", "").strip()
    frontend_url = None
    if fe_share_base:
        if "{token}" in fe_share_base:
            frontend_url = fe_share_base.replace("{token}", token)
        else:
            frontend_url = f"{fe_share_base.rstrip('/')}/{token}"
    expires_at = timezone.now() + timedelta(minutes=expires)

    if scope == ShareScope.CUSTOM and not custom_emails:
        return Response({"error": "Vui l�ng nh?p �t nh?t m?t email cho ch? d? ngu?i b?n ch?n"}, status=400)

    link_obj = PublicShareLink.objects.create(
        bucket=bucket,
        owner=user,
        storage_object=obj,
        token=token,
        expires_at=expires_at,
        requires_passcode=bool(token_passcode),
        scope=scope,
        allow_edit=allow_edit,
        custom_emails=custom_emails or None,
    )

    if scope == ShareScope.CUSTOM and custom_emails:
        subject = f"B?n du?c chia s? file: {obj.key}"
        body_lines = [
            f"{getattr(user, 'full_name', user.email)} d� chia s? file t?i b?n.",
            f"�u?ng d?n: {frontend_url or share_url}",
        ]
        if token_passcode:
            body_lines.append(f"Passcode: {token_passcode}")
        body_lines.append(f"H?t h?n: {expires_at.strftime('%Y-%m-%d %H:%M:%S')}")
        message = "\n".join(body_lines)
        try:
            send_mail(
                subject=subject,
                message=message,
                from_email=(getattr(user, "email", None) or getattr(settings, "DEFAULT_FROM_EMAIL", None)),
                recipient_list=custom_emails,
                fail_silently=True,
            )
        except Exception:
            pass

    office_url = None
    if _is_office_file(obj):
        office_url = f"https://view.officeapps.live.com/op/view.aspx?src={quote_plus(share_url)}"

    return Response(
        {
            "share_url": share_url,
            "frontend_url": frontend_url,
            "office_view_url": office_url,
            "expires_minutes": expires,
            "token": token,
        }
    )


@extend_schema(
    tags=["Share"],
    summary="Danh s�ch bucket du?c chia s? v?i t�i",
    responses={200: SharedWithMeSerializer(many=True)},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def list_shared_with_me(request):
    cache_key = _ck("shared_with_me", request.user.id)
    cached = cache.get(cache_key)
    if cached is not None:
        return Response(cached)

    queryset = AccessControlList.objects.filter(grantee=request.user).select_related(
        "bucket__owner"
    )
    serializer = SharedWithMeSerializer(queryset, many=True)
    data = serializer.data
    cache.set(cache_key, data, timeout=60)
    return Response(data)


@extend_schema(
    tags=["Share"],
    summary="Danh s�ch link t�i d� chia s?",
    responses={200: PublicShareLinkSerializer(many=True)},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def list_my_share_links(request):
    queryset = PublicShareLink.objects.filter(owner=request.user).select_related("storage_object")
    serializer = PublicShareLinkSerializer(queryset, many=True, context={"request": request})
    return Response(serializer.data)


@extend_schema(
    tags=["Share"],
    summary="Thu h?i link chia s?",
    responses={200: OpenApiResponse(description="Revoked"), 404: OpenApiResponse(description="Not found")},
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def revoke_share_link(request, token):
    link = get_object_or_404(PublicShareLink, token=token)
    if link.owner != request.user:
        return Response({"error": "B?n kh�ng c� quy?n thu h?i link n�y"}, status=403)
    link.delete()
    return Response({"message": "Share link revoked"}, status=200)


@extend_schema(
    tags=["Share"],
    summary="T?i file th�ng qua token chia s?",
    parameters=[
        OpenApiParameter(
            name="token",
            description="Token chia s?",
            required=True,
            type=OpenApiTypes.STR,
            location=OpenApiParameter.PATH,
        )
    ],
    responses={200: OpenApiResponse(description="File stream"), 400: OpenApiResponse(description="Invalid/expired token")},
)
@api_view(["GET"])
@permission_classes([permissions.AllowAny])
def shared_object_download(request, token):
    try:
        payload = _load_share_token(token)
    except ValueError as exc:
        return Response({"error": str(exc)}, status=400)

    bucket = get_object_or_404(Bucket, name=payload["bucket"])
    obj = get_object_or_404(StorageObject, bucket=bucket, key=payload["key"], is_deleted=False)
    share_record = PublicShareLink.objects.filter(token=token, storage_object=obj).first()
    if not share_record:
        return Response({"error": "Link kh�ng t?n t?i ho?c d� b? thu h?i"}, status=404)
    if share_record.is_expired():
        return Response({"error": "Link d� h?t h?n"}, status=410)

    def _login_redirect():
        fe_share_base = getattr(settings, "FRONTEND_SHARE_URL", "").strip()
        next_url = None
        if fe_share_base:
            if "{token}" in fe_share_base:
                next_url = fe_share_base.replace("{token}", token)
            else:
                next_url = f"{fe_share_base.rstrip('/')}/{token}"
        login_url = getattr(settings, "FRONTEND_LOGIN_URL", None)
        if login_url and next_url:
            return HttpResponseRedirect(f"{login_url}?next={next_url}")
        if login_url:
            return HttpResponseRedirect(login_url)
        return Response({"error": "Y�u c?u dang nh?p d? truy c?p link n�y"}, status=401)

    if share_record.scope == ShareScope.SIGNED:
        if not request.user or not request.user.is_authenticated:
            return _login_redirect()
        if request.user != share_record.owner and not AccessControlList.objects.filter(
            bucket=bucket, grantee=request.user
        ).exists():
            return Response({"error": "B?n kh�ng c� quy?n truy c?p link n�y"}, status=403)

    if share_record.scope == ShareScope.CUSTOM:
        if not request.user or not request.user.is_authenticated:
            return _login_redirect()
        allowed = {email.lower() for email in (share_record.custom_emails or [])}
        if (
            request.user != share_record.owner
            and request.user.email.lower() not in allowed
        ):
            return Response({"error": "B?n kh�ng n?m trong danh s�ch ngu?i nh?n"}, status=403)

    if request.GET.get("meta") == "1":
        return Response({
            "bucket": bucket.name,
            "key": obj.key,
            "name": os.path.basename(obj.key),
            "content_type": obj.content_type,
            "size": obj.size,
            "scope": share_record.scope if share_record else ShareScope.ANYONE,
            "allow_edit": getattr(share_record, "allow_edit", False),
            "requires_passcode": obj.encryption_type == EncryptionType.AES256,
            "owner_email": getattr(obj.owner, "email", None),
            "share_url": _build_public_url(reverse("shared_object_download", args=[token]), request),
        })

    temp_plain = None
    read_path = obj.storage_path
    metadata = obj.user_metadata or {}
    stored_passcode = payload.get("passcode") or metadata.get("passcode")

    raw_mode = request.GET.get("raw") == "1"

    try:
        if obj.encryption_type == EncryptionType.AES256:
            if not stored_passcode:
                return Response({"error": "File n�y y�u c?u passcode"}, status=400)
            fd, temp_plain = tempfile.mkstemp()
            os.close(fd)
            try:
                helpers.decrypt_file(obj.storage_path, temp_plain, stored_passcode)
            except Exception:
                os.remove(temp_plain)
                return Response({"error": "Kh�ng th? gi?i m� file"}, status=400)
            read_path = temp_plain

        mime = _normalize_office_mime(obj, obj.content_type or helpers.detect_mime_type(obj.key))

        if not raw_mode and _is_office_file(obj):
            base_share_path = reverse("shared_object_download", args=[token])
            raw_url = _build_public_url(f"{base_share_path}?raw=1", request)
            if "ngrok" in raw_url:
                separator = "&" if "?" in raw_url else "?"
                raw_url = f"{raw_url}{separator}ngrok-skip-browser-warning=true"
            office_url = f"https://view.officeapps.live.com/op/view.aspx?src={quote_plus(raw_url)}"
            return HttpResponseRedirect(office_url)

        response = FileResponse(open(read_path, "rb"), content_type=mime)
        disposition = f'inline; filename="{os.path.basename(obj.key)}"'
        response["Content-Disposition"] = disposition
        return response
    finally:
        if temp_plain and os.path.exists(temp_plain):
            try:
                os.remove(temp_plain)
            except Exception:
                pass


@extend_schema(
    tags=["Share"],
    summary="Luu n?i dung m?i cho file qua token chia s?",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Saved"), 400: OpenApiResponse(description="Invalid request")},
    examples=[
        OpenApiExample(
            "edit_via_token",
            value={"content": "new content", "passcode": "123456"},
            request_only=True,
        )
    ],
)
@api_view(["POST"])
@permission_classes([permissions.AllowAny])
@parser_classes([JSONParser])
def shared_object_save_version(request, token):
    """
    Cho ph�p ngu?i du?c chia s? (c� quy?n ch?nh s?a) luu n?i dung m?i.
    B?t bu?c dang nh?p tru?c khi ch?nh s?a.
    """
    if not request.user or not request.user.is_authenticated:
        return Response({"error": "Y�u c?u dang nh?p d? ch?nh s?a file du?c chia s?"}, status=401)

    try:
        payload = _load_share_token(token)
    except ValueError as exc:
        return Response({"error": str(exc)}, status=400)

    bucket = get_object_or_404(Bucket, name=payload["bucket"])
    obj = get_object_or_404(StorageObject, bucket=bucket, key=payload["key"], is_deleted=False)
    share_record = PublicShareLink.objects.filter(token=token, storage_object=obj).first()
    if not share_record:
        return Response({"error": "Link kh�ng t?n t?i ho?c d� b? thu h?i"}, status=404)
    if share_record.is_expired():
        return Response({"error": "Link d� h?t h?n"}, status=410)

    # Ki?m tra scope
    if share_record.scope == ShareScope.SIGNED:
        if request.user != share_record.owner and not AccessControlList.objects.filter(
            bucket=bucket, grantee=request.user
        ).exists():
            return Response({"error": "B?n kh�ng c� quy?n ch?nh s?a link n�y"}, status=403)
    if share_record.scope == ShareScope.CUSTOM:
        allowed = {email.lower() for email in (share_record.custom_emails or [])}
        if request.user != share_record.owner and request.user.email.lower() not in allowed:
            return Response({"error": "B?n kh�ng n?m trong danh s�ch ngu?i nh?n"}, status=403)

    if not share_record.allow_edit:
        return Response({"error": "Link n�y kh�ng cho ph�p ch?nh s?a"}, status=403)

    new_content = request.data.get("content")
    if new_content is None:
        return Response({"error": "Thi?u n?i dung m?i"}, status=400)

    passcode = (request.data.get("passcode") or "").strip()
    if passcode and (not passcode.isdigit() or len(passcode) != 6):
        return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)

    mime = _normalize_office_mime(obj, obj.content_type or helpers.detect_mime_type(obj.key))
    if not _is_text_mime(mime):
        return Response({"error": "Ch? h? tr? ch?nh s?a t?p van b?n qua link chia s?"}, status=400)

    metadata = obj.user_metadata or {}
    stored_passcode = (metadata.get("passcode") or "").strip()
    effective_passcode = passcode or stored_passcode
    if obj.encryption_type == EncryptionType.AES256:
        if stored_passcode and passcode and passcode != stored_passcode:
            return Response({"error": "Passcode kh�ng d�ng"}, status=400)
        if not effective_passcode:
            return Response({"error": "File n�y y�u c?u passcode"}, status=400)

    with transaction.atomic():
        # Luu version cu n?u c� file g?c
        ObjectVersion.objects.filter(object=obj, is_latest=True).update(is_latest=False)

        snapshot_path = obj.storage_path
        if os.path.exists(snapshot_path):
            backup_path = f"{snapshot_path}.v{uuid.uuid4().hex[:8]}"
            helpers.copy_local_file(snapshot_path, backup_path)
            snapshot_path = backup_path

        ObjectVersion.objects.create(
            object=obj,
            size=obj.size,
            etag=obj.etag,
            storage_path=snapshot_path,
            is_latest=False,
        )

        content_file = ContentFile(new_content.encode("utf-8"), name=os.path.basename(obj.key))
        result = helpers.save_file_to_local(
            bucket_name=bucket.name,
            key=obj.key,
            uploaded_file=content_file,
            passcode=(effective_passcode or None),
        )

        obj.storage_path = result["storage_path"]
        obj.size = result["size"]
        obj.etag = result["etag"]
        obj.content_type = result["content_type"]
        obj.encryption_type = EncryptionType.AES256 if effective_passcode else EncryptionType.NONE
        obj.status_encrypt = bool(effective_passcode)
        metadata.update({
            "encryption_type": obj.encryption_type,
            "salt_b64": result.get("salt_b64"),
        })
        if effective_passcode:
            metadata["passcode"] = effective_passcode
        elif "passcode" in metadata:
            metadata.pop("passcode", None)
        obj.user_metadata = metadata
        obj.last_modified = timezone.now()
        obj.save()

        helpers.log_change(request.user.id, bucket, obj.key, "modified")

    return Response({"message": "�� luu phi�n b?n m?i"})
# =====================================================
# ?? UPLOAD FILE
# =====================================================

@extend_schema(
    tags=["Objects"],
    summary="Preview object content",
    request=OpenApiTypes.OBJECT,
    responses={
        200: OpenApiResponse(description="Preview data"),
        400: OpenApiResponse(description="Invalid request"),
    },
    examples=[
        OpenApiExample(
            "preview_req",
            value={"key": "folder/file.txt", "passcode": "123456"},
            request_only=True,
        )
    ],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def preview_object(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n v?i bucket n�y"}, status=403)

    key = (request.data.get("key") or "").strip()
    if not key:
        return Response({"error": "Thi?u key"}, status=400)

    obj = get_object_or_404(StorageObject, bucket=bucket, key=key, is_deleted=False)
    is_encrypted = obj.encryption_type == EncryptionType.AES256
    metadata = obj.user_metadata or {}
    stored_passcode = (metadata.get("passcode") or "").strip()
    incoming_passcode = (request.data.get("passcode") or "").strip()
    if incoming_passcode and (not incoming_passcode.isdigit() or len(incoming_passcode) != 6):
        return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)
    effective_passcode = incoming_passcode or stored_passcode
    if is_encrypted:
        if stored_passcode and incoming_passcode and incoming_passcode != stored_passcode:
            return Response({"error": "Passcode kh�ng d�ng"}, status=400)
        if not effective_passcode:
            return Response({"error": "File n�y y�u c?u passcode"}, status=400)

    temp_plain = None
    read_path = obj.storage_path
    try:
        if is_encrypted:
            fd, temp_plain = tempfile.mkstemp()
            os.close(fd)
            try:
                helpers.decrypt_file(obj.storage_path, temp_plain, effective_passcode)
            except Exception:
                os.remove(temp_plain)
                return Response({"error": "Passcode kh�ng ch�nh x�c"}, status=400)
            read_path = temp_plain

        mime = obj.content_type or helpers.detect_mime_type(obj.key)
        if _is_text_mime(mime):
            with open(read_path, "r", encoding="utf-8", errors="replace") as f:
                content = f.read()
            return Response({
                "name": obj.key,
                "content": content,
                "content_type": mime,
                "is_text": True,
                "size": obj.size,
            })

        with open(read_path, "rb") as f:
            encoded = base64.b64encode(f.read()).decode()
        return Response({
            "name": obj.key,
            "content_base64": encoded,
            "content_type": mime,
            "is_text": False,
            "size": obj.size,
        })
    finally:
        if temp_plain and os.path.exists(temp_plain):
            try:
                os.remove(temp_plain)
            except Exception:
                pass


@extend_schema(
    tags=["Objects"],
    summary="Save new object version",
    request=OpenApiTypes.OBJECT,
    responses={
        200: OpenApiResponse(description="Saved"),
        400: OpenApiResponse(description="Invalid request"),
    },
    examples=[
        OpenApiExample(
            "save_req",
            value={"key": "folder/file.txt", "passcode": "123456", "content": "new content"},
            request_only=True,
        )
    ],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def save_object_version(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n v?i bucket n�y"}, status=403)

    key = (request.data.get("key") or "").strip()
    new_content = request.data.get("content")
    passcode = (request.data.get("passcode") or "").strip()

    if not key:
        return Response({"error": "Thi?u key"}, status=400)
    if new_content is None:
        return Response({"error": "Thi?u n?i dung m?i"}, status=400)
    if passcode and (not passcode.isdigit() or len(passcode) != 6):
        return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)

    obj = get_object_or_404(StorageObject, bucket=bucket, key=key, is_deleted=False)
    mime = _normalize_office_mime(obj, obj.content_type or helpers.detect_mime_type(obj.key))
    if not _is_text_mime(mime):
        return Response({"error": "Ch? h? tr? ch?nh s?a t?p van b?n"}, status=400)

    with transaction.atomic():
        ObjectVersion.objects.filter(object=obj, is_latest=True).update(is_latest=False)

        snapshot_path = obj.storage_path
        if os.path.exists(snapshot_path):
            backup_path = f"{snapshot_path}.v{uuid.uuid4().hex[:8]}"
            helpers.copy_local_file(snapshot_path, backup_path)
            snapshot_path = backup_path

        ObjectVersion.objects.create(
            object=obj,
            size=obj.size,
            etag=obj.etag,
            storage_path=snapshot_path,
            is_latest=False,
        )

        content_file = ContentFile(new_content.encode("utf-8"), name=os.path.basename(obj.key))
        result = helpers.save_file_to_local(
            bucket_name=bucket.name,
            key=obj.key,
            uploaded_file=content_file,
            passcode=(passcode or None),
        )

        obj.storage_path = result["storage_path"]
        obj.size = result["size"]
        obj.etag = result["etag"]
        obj.content_type = result["content_type"]
        obj.encryption_type = EncryptionType.AES256 if passcode else EncryptionType.NONE
        obj.status_encrypt = bool(passcode)
        metadata = obj.user_metadata or {}
        metadata.update({
            "encryption_type": obj.encryption_type,
            "salt_b64": result.get("salt_b64"),
        })
        if passcode:
            metadata["passcode"] = passcode
        elif "passcode" in metadata:
            metadata.pop("passcode", None)
        obj.user_metadata = metadata
        obj.save()

        helpers.log_change(user.id, bucket, obj.key, "modified")

    return Response({"message": "�� luu phi�n b?n m?i"})


@extend_schema(
    tags=["Objects"],
    summary="Upload single object",
    request={'multipart/form-data': OpenApiTypes.OBJECT},
    responses={201: OpenApiResponse(description="Created"), 200: OpenApiResponse(description="Updated"), 400: OpenApiResponse(description="Validation error")},
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([MultiPartParser, FormParser])
def upload_object(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)

    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n upload file"}, status=403)

    file_obj = request.FILES.get("file")
    key = request.data.get("key") or (file_obj.name if file_obj else None)
    passcode = (request.data.get("passcode") or "").strip()
    if passcode and (not passcode.isdigit() or len(passcode) != 6):
        return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)
    encryption_type = EncryptionType.AES256 if passcode else EncryptionType.NONE

    if not key or not file_obj:
        return Response({"error": "Thi?u key ho?c file"}, status=400)


    folder_path = os.path.dirname(key).strip()
    if folder_path and folder_path != ".":
        ensure_folder_entries(bucket, folder_path, bucket.owner)

    created = False
    action = "created"
    with transaction.atomic():
        try:
            obj = StorageObject.objects.get(bucket=bucket, key=key, is_deleted=False)
            action = "modified"

            if bucket.versioning_enabled:
                ObjectVersion.objects.filter(object=obj, is_latest=True).update(is_latest=False)

        except StorageObject.DoesNotExist:
            obj = StorageObject.objects.create(bucket=bucket, key=key, owner=bucket.owner)
            created = True
            action = "created"

   
        base_dir = helpers.ensure_bucket_folder(bucket.name)
        physical_dir = os.path.join(base_dir, os.path.dirname(key))
        os.makedirs(physical_dir, exist_ok=True)
        target_path = os.path.join(physical_dir, os.path.basename(key))


        res = helpers.save_file_to_local(
            bucket_name=bucket.name,
            key=key,
            uploaded_file=file_obj,
            passcode=(passcode if encryption_type == EncryptionType.AES256 else None),
            custom_path=target_path
        )

        obj.etag = res["etag"]
        obj.size = res["size"]
        obj.storage_path = res["storage_path"]
        obj.content_type = res["content_type"]
        metadata = obj.user_metadata or {}
        metadata.update({
            "encryption_type": encryption_type,
            "salt_b64": res.get("salt_b64"),
        })
        if passcode:
            metadata["passcode"] = passcode
        elif "passcode" in metadata:
            metadata.pop("passcode", None)
        obj.user_metadata = metadata
        obj.encryption_type = encryption_type
        obj.status_encrypt = encryption_type == EncryptionType.AES256
        obj.save()

        version_id = None
        if bucket.versioning_enabled:
            version_id = uuid.uuid4().hex[:12]
            ObjectVersion.objects.create(
                object=obj,
                version_id=version_id,
                etag=res["etag"],
                size=res["size"],
                storage_path=res["storage_path"],
                is_latest=True
            )

       
        ObjectChangeLog.objects.create(
            bucket=bucket,
            key=key,
            action=action,
            user=user,
            size=res["size"],
            version_id=version_id
        )

    try:
        invalidate_bucket_caches(bucket, user.id)
        cache.delete_many([
            _ck("object_meta", bucket.name, key),
            _ck("versions", bucket.name, key),
        ])
    except Exception:
        pass

    # Kh?i t?o job n?n d? t?o preview/thumbnail cho file v?a upload
    try:
        build_preview_async.delay(obj.id)
    except Exception:
        pass

    return Response({
        "message": "File uploaded",
        "key": key,
        "version_id": version_id,
        "size": res["size"],
        "encrypted": encryption_type != EncryptionType.NONE,
        "created": created
    }, status=201 if created else 200)


# =====================================================
# ?? DOWNLOAD FILE
# =====================================================
@extend_schema(
    tags=["Objects"],
    summary="Download object",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="File download"), 404: OpenApiResponse(description="Not found")},
    examples=[OpenApiExample("payload", value={"key": "test/abc/Logo TL.png", "passcode": "123456"}, request_only=True)],
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def download_object(request, bucket_name):
    """
    Download object from bucket.
    JSON body or query param:
    {
        "key": "test/abc/Logo TL.png",
        "passcode": "123456" 
    }
    """
    user = request.user
    key = request.data.get("key") or request.GET.get("key")
    if not key:
        return Response({"error": "Missing 'key'"}, status=400)

    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n download"}, status=403)

    obj = get_object_or_404(StorageObject, bucket=bucket, key=key, is_deleted=False)
    if not os.path.exists(obj.storage_path):
        return Response({"error": "File not found"}, status=404)

    if obj.encryption_type == EncryptionType.AES256:
        metadata = obj.user_metadata or {}
        stored_passcode = (metadata.get("passcode") or "").strip()
        incoming_passcode = (request.data.get("passcode") or request.GET.get("passcode") or request.headers.get("X-PASSCODE") or "").strip()
        if incoming_passcode and (not incoming_passcode.isdigit() or len(incoming_passcode) != 6):
            return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)
        if stored_passcode and incoming_passcode and incoming_passcode != stored_passcode:
            return Response({"error": "Invalid passcode"}, status=400)
        effective_passcode = incoming_passcode or stored_passcode
        if not effective_passcode:
            return Response({"error": "Passcode required for AES256"}, status=400)
        tmp_fd, tmp_path = tempfile.mkstemp()
        os.close(tmp_fd)
        try:
            helpers.decrypt_file(obj.storage_path, tmp_path, effective_passcode)
            return FileResponse(open(tmp_path, "rb"), as_attachment=True, filename=os.path.basename(key))
        except InvalidToken:
            return Response({"error": "Invalid passcode"}, status=400)
        finally:
            try: os.remove(tmp_path)
            except: pass

    return FileResponse(open(obj.storage_path, "rb"), as_attachment=True, filename=os.path.basename(key))


# =====================================================
# ? DELETE FILE
# =====================================================
@extend_schema(
    tags=["Objects"],
    summary="Delete object (soft)",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Deleted"), 404: OpenApiResponse(description="Not found")},
    examples=[OpenApiExample("payload", value={"key": "test/Picture1.png"}, request_only=True)],
)
@api_view(["DELETE"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def delete_object(request, bucket_name):
    """
    Delete object (soft delete). 
    JSON body:
    {
        "key": "test/Picture1.png"
    }
    """
    user = request.user
    key = request.data.get("key")
    if not key:
        return Response({"error": "Missing 'key' in request body"}, status=400)

    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n delete"}, status=403)

    obj = get_object_or_404(StorageObject, bucket=bucket, key=key, is_deleted=False)


    helpers.log_change(
        bucket=bucket,
        key=key,
        action="delete",
        user_id=bucket.owner.id,
        size=obj.size,
        version_id=None
    )


    obj.delete(hard=False)

    try:
        invalidate_bucket_caches(bucket, user.id)
        cache.delete_many([
            _ck("object_meta", bucket.name, key),
            _ck("versions", bucket.name, key),
        ])
    except Exception:
        pass

    return Response({"message": f"Soft deleted {bucket_name}/{key}"}, status=200)


# =====================================================
# ?? COPY / MOVE / RENAME FILE
# =====================================================
@extend_schema(
    tags=["Objects"],
    summary="Copy object",
    request=OpenApiTypes.OBJECT,
    responses={201: ObjectSerializer, 400: OpenApiResponse(description="Validation error"), 409: OpenApiResponse(description="Conflict")},
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def copy_object(request, bucket_name):
    """
    Copy object to another key (optionally another bucket).
    JSON body:
    {
        "old_key": "Documents/PT-TK-OO-5.pdf",
        "dest_bucket": "my-private-bucket", 
        "dest_key": "Documents/PT-TK-OO-5-copy.pdf"  # optional if same folder, auto rename
    }
    """
    user = request.user
    old_key = request.data.get("old_key")
    dest_bucket_name = request.data.get("dest_bucket", bucket_name)
    dest_key = request.data.get("dest_key")

    if not old_key:
        return Response({"error": "old_key is required"}, status=400)

    src_bucket = get_object_or_404(Bucket, name=bucket_name)
    if src_bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n copy"}, status=403)

    dest_bucket = get_object_or_404(Bucket, name=dest_bucket_name)
    obj = get_object_or_404(StorageObject, bucket=src_bucket, key=old_key, is_deleted=False)

    if not dest_key:
        dest_key = old_key

    dest_folder = os.path.dirname(dest_key).strip()
    if dest_folder and dest_folder != ".":
        if not dest_folder.endswith("/"):
            dest_folder += "/"
        if not StorageFolder.objects.filter(bucket=dest_bucket, path=dest_folder, is_deleted=False).exists():
            return Response({"error": f"Folder '{dest_folder}' kh�ng t?n t?i"}, status=400)

    base_name = os.path.splitext(os.path.basename(dest_key))[0]
    ext = os.path.splitext(dest_key)[1]

    final_key = dest_key
    counter = 1
    while StorageObject.objects.filter(bucket=dest_bucket, key=final_key, is_deleted=False).exists():
        final_key = os.path.join(dest_folder, f"{base_name} ({counter}){ext}")
        counter += 1

    dest_key = final_key


    base_dir = helpers.ensure_bucket_folder(dest_bucket.name)
    physical_dest_dir = os.path.join(base_dir, os.path.dirname(dest_key))
    os.makedirs(physical_dest_dir, exist_ok=True)

    src_path = obj.storage_path
    filename = os.path.basename(dest_key)

    if obj.status_encrypt and not src_path.endswith(".enc"):
        src_path += ".enc"
    if obj.status_encrypt and not filename.endswith(".enc"):
        filename += ".enc"

    dest_path = os.path.join(physical_dest_dir, filename)
    import shutil
    try:
        shutil.copy2(src_path, dest_path)
    except FileNotFoundError:
        return Response({"error": "File v?t l� kh�ng t?n t?i"}, status=500)

    new_obj = StorageObject.objects.create(
        bucket=dest_bucket,
        key=dest_key,
        owner=obj.owner,
        etag=obj.etag,
        size=obj.size,
        storage_path=dest_path,
        content_type=obj.content_type,
        user_metadata=obj.user_metadata,
        encryption_type=obj.encryption_type,
        status_encrypt=obj.status_encrypt,
    )

    helpers.log_change(
        bucket=dest_bucket,
        key=dest_key,
        action="copy",
        user_id=user.id,
        size=new_obj.size,
        version_id=None
    )

    try:
        invalidate_bucket_caches(dest_bucket, user.id)
        cache.delete_many([
            _ck("object_meta", dest_bucket.name, dest_key),
            _ck("versions", dest_bucket.name, dest_key),
        ])
    except Exception:
        pass

    return Response(ObjectSerializer(new_obj).data, status=201)


@extend_schema(
    tags=["Objects"],
    summary="Rename object",
    request=OpenApiTypes.OBJECT,
    responses={200: ObjectSerializer, 400: OpenApiResponse(description="Validation error"), 409: OpenApiResponse(description="Conflict")},
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def rename_object(request, bucket_name):
    user = request.user

    old_key = request.data.get("old_key")
    new_key = request.data.get("new_key")

    if not old_key or not new_key:
        return Response({"error": "Missing old_key or new_key"}, status=400)

    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n rename"}, status=403)

    obj = get_object_or_404(StorageObject, bucket=bucket, key=old_key, is_deleted=False)

 
    if StorageObject.objects.filter(bucket=bucket, key=new_key, is_deleted=False).exists():
        return Response({"error": "Object with that key already exists"}, status=409)

    new_folder = os.path.dirname(new_key).strip()
    if new_folder and new_folder != ".":
        if not new_folder.endswith("/"):
            new_folder += "/"

        exists = StorageFolder.objects.filter(
            bucket=bucket,
            path=new_folder,
            is_deleted=False
        ).exists()

        if not exists:
            return Response({"error": f"Folder '{new_folder}' kh�ng t?n t?i"}, status=400)

    old_path = obj.storage_path

    base_dir = helpers.ensure_bucket_folder(bucket.name)
    physical_new_dir = os.path.join(base_dir, os.path.dirname(new_key))
    os.makedirs(physical_new_dir, exist_ok=True)

    filename = os.path.basename(new_key)

    if obj.status_encrypt:  
        if not old_path.endswith(".enc"):
            old_path += ".enc"
        if not filename.endswith(".enc"):
            filename += ".enc"

    new_path = os.path.join(physical_new_dir, filename)

    os.rename(old_path, new_path)


    obj.key = new_key
    obj.storage_path = new_path
    obj.last_modified = timezone.now()
    obj.save(update_fields=["key", "storage_path", "last_modified"])

    helpers.log_change(
        bucket=bucket,
        key=new_key,
        action="rename",
        user_id=user.id,
        size=obj.size,
        version_id=None,
    )
    try:
        invalidate_bucket_caches(bucket, user.id)
        cache.delete_many([
            _ck("object_meta", bucket.name, old_key),
            _ck("object_meta", bucket.name, new_key),
            _ck("versions", bucket.name, old_key),
            _ck("versions", bucket.name, new_key),
        ])
    except Exception:
        pass
    return Response(ObjectSerializer(obj).data)

@extend_schema(
    tags=["Objects"],
    summary="Move object",
    request=OpenApiTypes.OBJECT,
    responses={200: ObjectSerializer, 400: OpenApiResponse(description="Validation error"), 409: OpenApiResponse(description="Conflict")},
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def move_object(request, bucket_name):
    """
    Move object within the same bucket or to another bucket folder.
    JSON body:
    {
        "old_key": "test/images/images.jpg",
        "dest_bucket": "my-private-bucket",  # optional
        "dest_key": "test/images/images.jpg"
    }
    """
    user = request.user
    old_key = request.data.get("old_key")
    dest_bucket_name = request.data.get("dest_bucket", bucket_name)
    dest_key = request.data.get("dest_key")

    if not old_key or not dest_key:
        return Response({"error": "old_key and dest_key are required"}, status=400)

    src_bucket = get_object_or_404(Bucket, name=bucket_name)
    if src_bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n move"}, status=403)

    dest_bucket = get_object_or_404(Bucket, name=dest_bucket_name)

    obj = get_object_or_404(StorageObject, bucket=src_bucket, key=old_key, is_deleted=False)


    dest_folder = os.path.dirname(dest_key).strip()
    if dest_folder and dest_folder != ".":
        if not dest_folder.endswith("/"):
            dest_folder += "/"
        if not StorageFolder.objects.filter(bucket=dest_bucket, path=dest_folder, is_deleted=False).exists():
            return Response({"error": f"Folder '{dest_folder}' kh�ng t?n t?i"}, status=400)


    if StorageObject.objects.filter(bucket=dest_bucket, key=dest_key, is_deleted=False).exists():
        return Response({"error": f"Object with key '{dest_key}' already exists in bucket '{dest_bucket.name}'"}, status=409)


    base_dir = helpers.ensure_bucket_folder(dest_bucket.name)
    physical_dest_dir = os.path.join(base_dir, os.path.dirname(dest_key))
    os.makedirs(physical_dest_dir, exist_ok=True)

    filename = os.path.basename(dest_key)

    old_path = obj.storage_path

    if obj.status_encrypt and not old_path.endswith(".enc"):
        old_path += ".enc"
    if obj.status_encrypt and not filename.endswith(".enc"):
        filename += ".enc"

    new_path = os.path.join(physical_dest_dir, filename)

    try:
        os.rename(old_path, new_path)
    except FileNotFoundError:
        return Response({"error": "File v?t l� kh�ng t?n t?i"}, status=500)

    with transaction.atomic():
        obj.bucket = dest_bucket
        obj.key = dest_key
        obj.storage_path = new_path
        obj.last_modified = timezone.now()
        obj.save(update_fields=["bucket", "key", "storage_path", "last_modified"])


        helpers.log_change(
            bucket=dest_bucket,
            key=dest_key,
            action="move",
            user_id=user.id,
            size=obj.size,
            version_id=None
        )

    try:
        # Invalidate both source and destination bucket caches
        invalidate_bucket_caches(src_bucket, user.id)
        invalidate_bucket_caches(dest_bucket, user.id)
        cache.delete_many([
            _ck("object_meta", src_bucket.name, old_key),
            _ck("object_meta", dest_bucket.name, dest_key),
            _ck("versions", src_bucket.name, old_key),
            _ck("versions", dest_bucket.name, dest_key),
        ])
    except Exception:
        pass

    return Response(ObjectSerializer(obj).data, status=200)


@extend_schema(
    tags=["Objects"],
    summary="Restore soft-deleted object",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Restored"), 404: OpenApiResponse(description="Not found")},
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
def restore_object(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)

   
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n"}, status=403)

    key = request.data.get("key")
    if not key:
        return Response({"error": "Thi?u key"}, status=400)

    try:
     
        obj = StorageObject.all_objects.get(bucket=bucket, key=key)
    except StorageObject.DoesNotExist:
        return Response({"error": "Kh�ng t�m th?y file"}, status=404)

    if not obj.is_deleted:
        return Response({"error": "File dang ? tr?ng th�i ho?t d?ng"}, status=400)


    obj.is_deleted = False
    obj.deleted_at = None
    obj.save(update_fields=["is_deleted", "deleted_at"])


    last_version = (
        ObjectVersion.objects.filter(object=obj)
        .order_by("-created_at")
        .first()
    )
    version_id = last_version.version_id if last_version else None

    ObjectChangeLog.objects.create(
        bucket=bucket,
        key=obj.key,
        action="restored",
        user=user,
        size=obj.size,
        version_id=version_id,
    )
    try:
        invalidate_bucket_caches(bucket, user.id)
        cache.delete_many([
            _ck("object_meta", bucket.name, key),
            _ck("versions", bucket.name, key),
        ])
    except Exception:
        pass

    return Response({
        "message": "Kh�i ph?c file th�nh c�ng",
        "key": key,
        "version_id": version_id,
    }, status=200)


@extend_schema(
    tags=["Trash"],
    summary="List recycle bin items",
    responses={200: TrashEntrySerializer(many=True)},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def list_trash_items(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n xem th�ng r�c"}, status=403)

    trashed_folders = StorageFolder.all_objects.filter(
        bucket=bucket, is_deleted=True
    )
    trashed_objects = StorageObject.all_objects.filter(
        bucket=bucket, is_deleted=True
    )

    entries = []
    for folder in trashed_folders:
        entries.append({
            "key": folder.path.rstrip("/"),
            "name": folder.name,
            "size": None,
            "content_type": "folder",
            "deleted_at": folder.deleted_at or timezone.now(),
            "is_folder": True,
        })

    for obj in trashed_objects:
        name = os.path.basename(obj.key.rstrip("/")) or obj.key
        entries.append({
            "key": obj.key,
            "name": name,
            "size": obj.size,
            "content_type": obj.content_type,
            "deleted_at": obj.deleted_at or timezone.now(),
            "is_folder": False,
        })

    entries.sort(key=lambda item: item["deleted_at"] or timezone.now(), reverse=True)
    serializer = TrashEntrySerializer(entries, many=True)
    return Response(serializer.data, status=200)


@extend_schema(
    tags=["Trash"],
    summary="Permanently delete an item from recycle bin",
    request=TrashDeleteRequestSerializer,
    responses={
        200: OpenApiResponse(description="Deleted"),
        400: OpenApiResponse(description="Validation error"),
        404: OpenApiResponse(description="Not found"),
    },
)
@api_view(["DELETE"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def hard_delete_trash_item(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n thao t�c th�ng r�c"}, status=403)

    serializer = TrashDeleteRequestSerializer(data=request.data)
    serializer.is_valid(raise_exception=True)

    key = serializer.validated_data["key"].strip()
    is_folder = serializer.validated_data.get("is_folder", False)

    if not key:
        return Response({"error": "Thi?u key"}, status=400)

    if is_folder:
        normalized = key.strip().lstrip("/").rstrip("/")
        if normalized:
            normalized = f"{normalized}/"
        else:
            return Response({"error": "Kh�ng th? x�a thu m?c g?c"}, status=400)

        try:
            folder = StorageFolder.all_objects.get(bucket=bucket, path=normalized)
        except StorageFolder.DoesNotExist:
            return Response({"error": "Kh�ng t�m th?y folder trong th�ng r�c"}, status=404)

        if not folder.is_deleted:
            return Response({"error": "Folder kh�ng n?m trong th�ng r�c"}, status=400)

        with transaction.atomic():
            nested_objects = list(StorageObject.all_objects.filter(
                bucket=bucket,
                key__startswith=folder.path
            ))
            for obj in nested_objects:
                _remove_physical_file(obj)
            StorageObject.all_objects.filter(
                bucket=bucket,
                key__startswith=folder.path
            ).delete()
            StorageFolder.all_objects.filter(
                bucket=bucket,
                path__startswith=folder.path
            ).delete()

        message = f"�� x�a vinh vi?n thu m?c {folder.path}"
    else:
        try:
            obj = StorageObject.all_objects.get(bucket=bucket, key=key)
        except StorageObject.DoesNotExist:
            return Response({"error": "Kh�ng t�m th?y file trong th�ng r�c"}, status=404)

        if not obj.is_deleted:
            return Response({"error": "File kh�ng n?m trong th�ng r�c"}, status=400)

        _remove_physical_file(obj)
        obj.delete(hard=True)
        message = f"�� x�a vinh vi?n file {key}"

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass

    return Response({"message": message}, status=200)

# ------------------- DOWNLOAD FILE -------------------
# ================== VIEW FILE INLINE ==================
# =====================================================
# ?? BUCKET DETAIL / DELETE / UPDATE
# =====================================================

@extend_schema(
    tags=["Buckets"],
    summary="Bucket detail",
    responses={200: BucketSerializer, 403: OpenApiResponse(description="Forbidden"), 404: OpenApiResponse(description="Not found")},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def get_bucket_detail(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n xem th�ng tin bucket n�y"}, status=403)
    cache_key = _ck("bucket_detail", bucket.name)
    data = cache.get(cache_key)
    if data is None:
        serializer = BucketSerializer(bucket, context={"request": request})
        data = serializer.data
        cache.set(cache_key, data, timeout=60)
    return Response(data)


@extend_schema(
    tags=["Buckets"],
    summary="Delete bucket",
    responses={200: OpenApiResponse(description="Deleted"), 400: OpenApiResponse(description="Bucket not empty")},
)
@api_view(["DELETE"])
@permission_classes([permissions.IsAuthenticated])
def delete_bucket(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n x�a bucket n�y"}, status=403)

  
    if bucket.objects.exists():
        return Response(
            {"error": "Kh�ng th? xo� bucket c�n ch?a object."}, status=400
        )

    try:
        invalidate_bucket_caches(bucket, user.id)
    except Exception:
        pass
    bucket.delete()
    return Response({"message": f"Bucket '{bucket_name}' d� du?c xo�."}, status=200)


@extend_schema(
    tags=["Buckets"],
    summary="Update bucket (partial)",
    request=BucketSerializer,
    responses={200: BucketSerializer, 400: OpenApiResponse(description="Validation error")},
)
@api_view(["PATCH"])
@permission_classes([permissions.IsAuthenticated])
def update_bucket(request, bucket_name):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n c?p nh?t bucket n�y"}, status=403)
    serializer = BucketSerializer(bucket, data=request.data, partial=True)
    if serializer.is_valid():
        serializer.save()
        try:
            invalidate_bucket_caches(bucket, user.id)
        except Exception:
            pass
        return Response(serializer.data)
    return Response(serializer.errors, status=400)


# =====================================================
# ?? OBJECT VERSIONING
# =====================================================

@extend_schema(
    tags=["Versions"],
    summary="List object versions",
    responses={200: ObjectVersionSerializer(many=True)},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def list_object_versions(request, bucket_name, key):
    user = request.user
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n xem version c?a object trong bucket n�y"}, status=403)
    obj = get_object_or_404(StorageObject, bucket=bucket, key=key)
    cache_key = _ck("versions", bucket.name, key)
    cached = cache.get(cache_key)
    if cached is not None:
        return Response(cached)
    versions = obj.versions.all().order_by("-created_at")
    data = ObjectVersionSerializer(versions, many=True).data
    cache.set(cache_key, data, timeout=120)
    return Response(data)


@extend_schema(
    tags=["Versions"],
    summary="Download a specific object version",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="File download"), 404: OpenApiResponse(description="Not found")},
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def download_object_version_post(request, bucket_name):
    """
    Download a specific version of an object via POST.
    Body:
    {
        "key": "path/to/file",
        "version_id": "abcdef123456",
        "passcode": "optional-if-AES256"
    }
    """
    user = request.user
    key = request.data.get("key")
    version_id = request.data.get("version_id")
    if not key:
        return Response({"error": "Missing 'key'"}, status=400)
    if not version_id:
        return Response({"error": "Missing 'version_id'"}, status=400)

    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n download"}, status=403)

    obj = get_object_or_404(StorageObject, bucket=bucket, key=key, is_deleted=False)
    version = get_object_or_404(ObjectVersion, object=obj, version_id=version_id)

    if not os.path.isfile(version.storage_path):
        return Response({"error": "Version file not found"}, status=404)

    if obj.encryption_type == EncryptionType.AES256:
        metadata = obj.user_metadata or {}
        stored_passcode = (metadata.get("passcode") or "").strip()
        incoming_passcode = (request.data.get("passcode") or request.GET.get("passcode") or request.headers.get("X-PASSCODE") or "").strip()
        if incoming_passcode and (not incoming_passcode.isdigit() or len(incoming_passcode) != 6):
            return Response({"error": "Passcode ph?i g?m d�ng 6 ch? s?"}, status=400)
        if stored_passcode and incoming_passcode and incoming_passcode != stored_passcode:
            return Response({"error": "Invalid passcode"}, status=400)
        effective_passcode = incoming_passcode or stored_passcode
        if not effective_passcode:
            return Response({"error": "Passcode required for AES256"}, status=400)
        tmp_fd, tmp_path = tempfile.mkstemp()
        os.close(tmp_fd)
        try:
            helpers.decrypt_file(version.storage_path, tmp_path, effective_passcode)
            return FileResponse(
                open(tmp_path, "rb"),
                as_attachment=True,
                filename=f"{os.path.basename(key)}.v{version.version_id}",
                content_type=obj.content_type,
            )
        except InvalidToken:
            return Response({"error": "Invalid passcode"}, status=400)
        finally:
            try:
                os.remove(tmp_path)
            except Exception:
                pass

    return FileResponse(
        open(version.storage_path, "rb"),
        as_attachment=True,
        filename=f"{os.path.basename(key)}.v{version.version_id}",
        content_type=obj.content_type,
    )


@extend_schema(
    tags=["Versions"],
    summary="Restore to a specific object version",
    request=OpenApiTypes.OBJECT,
    responses={200: OpenApiResponse(description="Restored with new_version_id"), 400: OpenApiResponse(description="Validation/disabled versioning")},
)
@api_view(["POST"])
@permission_classes([permissions.IsAuthenticated])
@parser_classes([JSONParser])
def restore_object_version_post(request, bucket_name):
    """
    Restore object to a specific version via POST.
    Body:
    {
        "key": "path/to/file",
        "version_id": "abcdef123456"
    }
    """
    user = request.user
    key = request.data.get("key")
    version_id = request.data.get("version_id")
    if not key:
        return Response({"error": "Missing 'key'"}, status=400)
    if not version_id:
        return Response({"error": "Missing 'version_id'"}, status=400)

    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n kh�i ph?c version c?a object trong bucket n�y"}, status=403)
    if not bucket.versioning_enabled:
        return Response({"error": "Bucket chua b?t versioning"}, status=400)

    obj = get_object_or_404(StorageObject, bucket=bucket, key=key)
    version = get_object_or_404(ObjectVersion, object=obj, version_id=version_id)

    if not os.path.isfile(version.storage_path):
        return Response({"error": "Version file not found"}, status=404)

    with transaction.atomic():

        ObjectVersion.objects.filter(object=obj, is_latest=True).update(is_latest=False)

    
        new_ver_id = uuid.uuid4().hex[:12]
        new_version = ObjectVersion.objects.create(
            object=obj,
            version_id=new_ver_id,
            etag=version.etag,
            size=version.size,
            storage_path=version.storage_path,
            is_latest=True,
        )

   
        obj.storage_path = version.storage_path
        obj.size = version.size
        obj.etag = version.etag
        obj.last_modified = timezone.now()
        obj.save(update_fields=["storage_path", "size", "etag", "last_modified"])

        ObjectChangeLog.objects.create(
            bucket=bucket,
            key=obj.key,
            action="restored",
            version_id=new_version.version_id,
            size=new_version.size,
            user=user,
        )

    return Response({
        "message": f"�� kh�i ph?c version {version_id} th�nh phi�n b?n m?i",
        "new_version_id": new_ver_id,
    })


# =====================================================
# ?? STATUS
# =====================================================

@extend_schema(
    tags=["Status"],
    summary="Bucket status summary",
    responses={200: OpenApiResponse(description="{ bucket, object_count, total_size }")},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def bucket_status(request, bucket_name):
    user = request.user 
    bucket = get_object_or_404(Bucket, name=bucket_name)
    if bucket.owner != user:
        return Response({"error": "B?n kh�ng c� quy?n xem status c?a bucket n�y"}, status=403)
    cache_key = _ck("bucket_status", bucket.name)
    cached = cache.get(cache_key)
    if cached is not None:
        return Response(cached)
    total_objects = bucket.objects.count()
    total_size = bucket.objects.aggregate(total=sum("size"))["total"] or 0
    data = {
        "bucket": bucket.name,
        "object_count": total_objects,
        "total_size": total_size,
    }
    cache.set(cache_key, data, timeout=30)
    return Response(data)


GB_IN_BYTES = 1024 * 1024 * 1024

@extend_schema(
    tags=["Status"],
    summary="User storage summary",
    responses={200: OpenApiResponse(description="{ bucket_count, object_count, total_size }")},
)
@api_view(["GET"])
@permission_classes([permissions.IsAuthenticated])
def user_storage_summary(request):
    cache_key = _ck("user_summary", request.user.id)
    cached = cache.get(cache_key)
    if cached is not None:
        return Response(cached)

    user_buckets = Bucket.objects.filter(owner=request.user.id)
    total_objects = sum(b.storage_objects.count() for b in user_buckets)
    total_size = sum(
        sum(o.size or 0 for o in b.storage_objects.all()) for b in user_buckets
    )
    user_limit = getattr(request.user, "storage_limit", 0) or 0
    user_used = total_size
    if getattr(request.user, "used_storage", None) != total_size:
        request.user.used_storage = total_size
        request.user.save(update_fields=["used_storage"])

    usage_percent = 0
    if user_limit > 0:
        usage_percent = round(min(100, (user_used / user_limit) * 100), 2)

    plan = getattr(request.user, "plan", "") or "free"
    plan_expiration = getattr(request.user, "plan_expiration", None)

    data = {
        "user": str(request.user.id),
        "bucket_count": user_buckets.count(),
        "object_count": total_objects,
        "total_size": total_size,
        "storage_limit": user_limit,
        "storage_limit_gb": round(user_limit / GB_IN_BYTES, 2),
        "used_storage": user_used,
        "used_storage_gb": round(user_used / GB_IN_BYTES, 2),
        "used_storage_percent": usage_percent,
        "plan": plan,
        "plan_expiration": plan_expiration,
    }
    cache.set(cache_key, data, timeout=30)
    return Response(data)


